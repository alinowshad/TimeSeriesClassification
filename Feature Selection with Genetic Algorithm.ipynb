{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. References \n",
    "\n",
    "This notebook heavily uses concepts and implementation of:\n",
    "* https://github.com/JingweiToo/Wrapper-Feature-Selection-Toolbox-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:53.537930Z",
     "iopub.status.busy": "2022-12-14T11:02:53.537548Z",
     "iopub.status.idle": "2022-12-14T11:02:53.547962Z",
     "shell.execute_reply": "2022-12-14T11:02:53.546471Z",
     "shell.execute_reply.started": "2022-12-14T11:02:53.537899Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16) \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import randrange\n",
    "import time\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:53.709093Z",
     "iopub.status.busy": "2022-12-14T11:02:53.708433Z",
     "iopub.status.idle": "2022-12-14T11:02:53.798900Z",
     "shell.execute_reply": "2022-12-14T11:02:53.797460Z",
     "shell.execute_reply.started": "2022-12-14T11:02:53.709060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:53.892229Z",
     "iopub.status.busy": "2022-12-14T11:02:53.891578Z",
     "iopub.status.idle": "2022-12-14T11:02:53.907539Z",
     "shell.execute_reply": "2022-12-14T11:02:53.906653Z",
     "shell.execute_reply.started": "2022-12-14T11:02:53.892186Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"/kaggle/input/homework2timeseries/x_train.npy\")\n",
    "y_train = np.load(\"/kaggle/input/homework2timeseries/y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:54.126126Z",
     "iopub.status.busy": "2022-12-14T11:02:54.125140Z",
     "iopub.status.idle": "2022-12-14T11:02:54.131479Z",
     "shell.execute_reply": "2022-12-14T11:02:54.130453Z",
     "shell.execute_reply.started": "2022-12-14T11:02:54.126087Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X_train Shape:\", x_train.shape)\n",
    "print(\"Y_train Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:54.369625Z",
     "iopub.status.busy": "2022-12-14T11:02:54.368975Z",
     "iopub.status.idle": "2022-12-14T11:02:54.374630Z",
     "shell.execute_reply": "2022-12-14T11:02:54.373599Z",
     "shell.execute_reply.started": "2022-12-14T11:02:54.369580Z"
    }
   },
   "outputs": [],
   "source": [
    "#x_train = x_train[0:, 0:25, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:54.410861Z",
     "iopub.status.busy": "2022-12-14T11:02:54.408873Z",
     "iopub.status.idle": "2022-12-14T11:02:54.421383Z",
     "shell.execute_reply": "2022-12-14T11:02:54.420499Z",
     "shell.execute_reply.started": "2022-12-14T11:02:54.410833Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:54.702444Z",
     "iopub.status.busy": "2022-12-14T11:02:54.702053Z",
     "iopub.status.idle": "2022-12-14T11:02:54.712223Z",
     "shell.execute_reply": "2022-12-14T11:02:54.711163Z",
     "shell.execute_reply.started": "2022-12-14T11:02:54.702404Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = tfk.utils.to_categorical(y_train)\n",
    "y_test = tfk.utils.to_categorical(y_test)\n",
    "y_val = tfk.utils.to_categorical(y_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:55.219540Z",
     "iopub.status.busy": "2022-12-14T11:02:55.218456Z",
     "iopub.status.idle": "2022-12-14T11:02:55.224993Z",
     "shell.execute_reply": "2022-12-14T11:02:55.224012Z",
     "shell.execute_reply.started": "2022-12-14T11:02:55.219495Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "classes = y_train.shape[-1]\n",
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:55.532545Z",
     "iopub.status.busy": "2022-12-14T11:02:55.531667Z",
     "iopub.status.idle": "2022-12-14T11:02:55.539316Z",
     "shell.execute_reply": "2022-12-14T11:02:55.538133Z",
     "shell.execute_reply.started": "2022-12-14T11:02:55.532504Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Long Short Term Memory (LSTM) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:56.463731Z",
     "iopub.status.busy": "2022-12-14T11:02:56.463352Z",
     "iopub.status.idle": "2022-12-14T11:02:56.474725Z",
     "shell.execute_reply": "2022-12-14T11:02:56.473580Z",
     "shell.execute_reply.started": "2022-12-14T11:02:56.463698Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_LSTM_classifier(input_shape, classes):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # Feature extractor\n",
    "    lstm = tfkl.Bidirectional(tfkl.LSTM(256, return_sequences=True))(input_layer)\n",
    "    lstm = tfkl.Bidirectional(tfkl.LSTM(512, return_sequences=True))(lstm)\n",
    "    Skip_LSTM = tfkl.LSTM(256, return_sequences=True)(input_layer)\n",
    "    #Skip_LSTM = tfkl.LSTM(128, return_sequences=True)(Skip_LSTM)\n",
    "\n",
    "    lstm = tfkl.GlobalMaxPooling1D()(lstm)\n",
    "    Skip_LSTM = tfkl.GlobalMaxPooling1D()(Skip_LSTM)\n",
    "    dropout = tfkl.Dropout(.3, seed=seed)(lstm)\n",
    "    Skip_LSTM = tfkl.Dropout(.3)(Skip_LSTM)\n",
    "    flatt=tfkl.concatenate([dropout,Skip_LSTM])\n",
    "    # Classifier\n",
    "    classifier = tfkl.Dense(256, activation='relu')(flatt)\n",
    "   # classifier = tfkl.Dense(64, activation='relu')(classifier)\n",
    "    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:02:56.900869Z",
     "iopub.status.busy": "2022-12-14T11:02:56.900176Z",
     "iopub.status.idle": "2022-12-14T11:02:58.219337Z",
     "shell.execute_reply": "2022-12-14T11:02:58.218331Z",
     "shell.execute_reply.started": "2022-12-14T11:02:56.900831Z"
    }
   },
   "outputs": [],
   "source": [
    "model_LSTM = build_LSTM_classifier(input_shape, classes)\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:38:46.731176Z",
     "iopub.status.busy": "2022-12-14T11:38:46.730792Z",
     "iopub.status.idle": "2022-12-14T11:38:46.741317Z",
     "shell.execute_reply": "2022-12-14T11:38:46.740340Z",
     "shell.execute_reply.started": "2022-12-14T11:38:46.731143Z"
    }
   },
   "outputs": [],
   "source": [
    "# error rate\n",
    "def error_rate(xtrain, ytrain, x, opts):\n",
    "    # parameters\n",
    "    k  = opts['k']\n",
    "    fold = opts['fold']\n",
    "    xt = fold['xt']\n",
    "    yt = fold['yt']\n",
    "    xv = fold['xv']\n",
    "    yv = fold['yv']\n",
    "    \n",
    "    # number of instances\n",
    "    num_train = np.size(xt, 0)\n",
    "    num_valid = np.size(xv, 0)\n",
    "    # Define selected features\n",
    "    xtrain = xt[:, x == 1, :]\n",
    "    xvalid = xv[:, x == 1, :]\n",
    "    # Training\n",
    "    input_shape = xtrain.shape[1:]\n",
    "    model_LSTM = build_LSTM_classifier(input_shape, 12)\n",
    "    # Train the model\n",
    "    history_LSTM = model_LSTM.fit(\n",
    "        [xtrain],\n",
    "        y = yt,\n",
    "        batch_size = 16,\n",
    "        epochs = 50,\n",
    "        validation_data=(xvalid, yv),\n",
    "        callbacks = [\n",
    "            tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience = 3, verbose=1,factor=0.3, min_lr=0.000001),\n",
    "            tfk.callbacks.ModelCheckpoint('LSTM.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "        ]\n",
    "    ).history\n",
    "    # Prediction\n",
    "    ypred   = model_LSTM.predict(xvalid)\n",
    "    acc     = np.sum(yv == ypred) / num_valid\n",
    "    error   = 1 - acc\n",
    "    \n",
    "    return error, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:38:53.602353Z",
     "iopub.status.busy": "2022-12-14T11:38:53.601961Z",
     "iopub.status.idle": "2022-12-14T11:38:53.608785Z",
     "shell.execute_reply": "2022-12-14T11:38:53.607509Z",
     "shell.execute_reply.started": "2022-12-14T11:38:53.602319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Error rate & Feature size\n",
    "def Fun(xtrain, ytrain, x, opts):\n",
    "    # parameters\n",
    "    alpha = 0.99\n",
    "    beta = 1 - alpha\n",
    "    # original feature size\n",
    "    max_feat = len(x)\n",
    "    # Number of selected features\n",
    "    num_feat = np.sum(x == 1)\n",
    "    # Solve if no feature selected\n",
    "    if num_feat == 0:\n",
    "        cost = 1\n",
    "    else:\n",
    "        # Get error rate\n",
    "        error, acc = error_rate(xtrain, ytrain, x, opts)\n",
    "        # Objective function\n",
    "        cost = alpha * error + beta * (num_feat / max_feat)\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:39:59.199163Z",
     "iopub.status.busy": "2022-12-14T11:39:59.198796Z",
     "iopub.status.idle": "2022-12-14T11:39:59.206463Z",
     "shell.execute_reply": "2022-12-14T11:39:59.204223Z",
     "shell.execute_reply.started": "2022-12-14T11:39:59.199132Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_position(lb, ub, N1, N2, dim):\n",
    "    X = np.zeros([N1, N2, dim], dtype='float')\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "                X[i,j,:] = lb[0,j,:] + (ub[0,j,:] - lb[0,j,:]) * rand()        \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:40:46.846313Z",
     "iopub.status.busy": "2022-12-14T11:40:46.845167Z",
     "iopub.status.idle": "2022-12-14T11:40:46.852930Z",
     "shell.execute_reply": "2022-12-14T11:40:46.851414Z",
     "shell.execute_reply.started": "2022-12-14T11:40:46.846241Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_conversion(X, thres, N1, N2, dim):\n",
    "    Xbin = np.zeros([N1, N2, dim], dtype='int')\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "                if X[i,j,:] > thres:\n",
    "                    Xbin[i,j,:] = 1\n",
    "                else:\n",
    "                    Xbin[i,j,:] = 0\n",
    "    \n",
    "    return Xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:40:50.083805Z",
     "iopub.status.busy": "2022-12-14T11:40:50.083119Z",
     "iopub.status.idle": "2022-12-14T11:40:50.091895Z",
     "shell.execute_reply": "2022-12-14T11:40:50.090903Z",
     "shell.execute_reply.started": "2022-12-14T11:40:50.083766Z"
    }
   },
   "outputs": [],
   "source": [
    "def roulette_wheel(prob):\n",
    "    num = len(prob)\n",
    "    C   = np.cumsum(prob)\n",
    "    P   = rand()\n",
    "    for i in range(num):\n",
    "        if C[i] > P:\n",
    "            index = i;\n",
    "            break\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:43:37.914611Z",
     "iopub.status.busy": "2022-12-14T11:43:37.914163Z",
     "iopub.status.idle": "2022-12-14T11:43:37.936240Z",
     "shell.execute_reply": "2022-12-14T11:43:37.935203Z",
     "shell.execute_reply.started": "2022-12-14T11:43:37.914578Z"
    }
   },
   "outputs": [],
   "source": [
    "def jfs(xtrain, ytrain, opts):\n",
    "    # Parameters\n",
    "    ub = 1\n",
    "    lb = 0\n",
    "    thres = 0.5\n",
    "    CR = 0.8  # crossover rate\n",
    "    MR = 0.01 # mutation rate\n",
    "    \n",
    "    N1 = opts['N']\n",
    "    N2 = 36\n",
    "    max_iter = opts['T']\n",
    "    if 'CR' in opts:\n",
    "        CR = opts['CR']\n",
    "    if 'MR' in opts:\n",
    "        MR = opts['MR']\n",
    "    \n",
    "    # Dimension\n",
    "    dim = np.size(xtrain, 2)\n",
    "    if np.size(lb) == 1:\n",
    "        ub = ub * np.ones([1, N2, dim], dtype='float')\n",
    "        lb = lb * np.ones([1, N2, dim], dtype='float')\n",
    "    \n",
    "    # Initialize position\n",
    "    X = init_position(lb, ub, N1, N2, dim)\n",
    "    \n",
    "    # Binary conversion\n",
    "    X = binary_conversion(X, thres, N1, N2, dim)\n",
    "    \n",
    "    # Fitness at first iteration\n",
    "    fit = np.zeros([N, 1], dtype='float')\n",
    "    Xgb = np.zeros([1, N2, dim], dtype='int')\n",
    "    fitG = float('inf')\n",
    "    \n",
    "    for i in range(N1):\n",
    "        fit[i, 0] = Fun(xtrain, ytrain, X[i, :, :], opts)\n",
    "        if fit[i, 0] < fitG:\n",
    "            Xgb[0, :, :] = X[i, :, :]\n",
    "            fitG = fit[i,0]\n",
    "    \n",
    "    # Pre\n",
    "    curve = np.zeros([1, max_iter], dtype='float')\n",
    "    t     = 0\n",
    "    \n",
    "    curve[0,t] = fitG.copy()\n",
    "    print(\"Generation:\", t + 1)\n",
    "    print(\"Best (GA):\", curve[0,t])\n",
    "    t += 1\n",
    "    \n",
    "    while t < max_iter:\n",
    "        # Probability\n",
    "        inv_fit = 1 / (1 + fit)\n",
    "        prob = inv_fit / np.sum(inv_fit)\n",
    "        # Number of crossovers\n",
    "        Nc = 0\n",
    "        for i in range(N1):\n",
    "            if rand() < CR:\n",
    "                Nc += 1\n",
    "        \n",
    "        x1 = np.zeros([Nc, N2, dim], dtype='int')\n",
    "        x2 = np.zeros([Nc, N2, dim], dtype='int')\n",
    "        for i in range(Nc):\n",
    "            # Parent selection\n",
    "            k1  = roulette_wheel(prob)\n",
    "            k2  = roulette_wheel(prob)\n",
    "            P1 = X[k1, :, :].copy()\n",
    "            P2 = X[k2, :, :].copy()\n",
    "            # Random one dimension from 1 to dim\n",
    "            index = np.random.randint(low=1, high=dim-1)\n",
    "            # Crossover\n",
    "            x1[i, :, :] = np.concatenate((P1[0:index], P2[index:]))\n",
    "            x2[i, :, :] = np.concatenate((P2[0:index], P1[index:]))\n",
    "            # Mutation\n",
    "            for j in range(N2):\n",
    "                if rand() < MR:\n",
    "                    x1[i,j,:] = 1 - x1[i,j,:]\n",
    "\n",
    "                if rand() < MR:\n",
    "                    x2[i,j,:] = 1 - x2[i,j,:]\n",
    "        # Merge two group into one\n",
    "        Xnew = np.concatenate((x1, x2), axis=0)\n",
    "            \n",
    "        # Fitness\n",
    "        Fnew = np.zeros([2 * Nc, 1], dtype='float')\n",
    "        for i in range(2 * Nc):\n",
    "            Fnew[i,0] = Fun(xtrain, ytrain, Xnew[i,:, :], opts)\n",
    "            if Fnew[i,0] < fitG:\n",
    "                Xgb[0,j,:] = Xnew[i,:,:]\n",
    "                fitG = Fnew[i,0]\n",
    "            \n",
    "        # Store result\n",
    "        curve[0,t] = fitG.copy()\n",
    "        print(\"Generation:\", t + 1)\n",
    "        print(\"Best (GA):\", curve[0,t])\n",
    "        t += 1\n",
    "            \n",
    "        # Elitism \n",
    "        XX  = np.concatenate((X , Xnew), axis=0)\n",
    "        FF  = np.concatenate((fit , Fnew), axis=0)\n",
    "        # Sort in ascending order\n",
    "        ind = np.argsort(FF, axis=0)\n",
    "        for i in range(N1):\n",
    "            X[i,:]   = XX[ind[i,0],:,:]\n",
    "            fit[i,0] = FF[ind[i,0]]\n",
    "\n",
    "    # Best feature subset\n",
    "    Gbin       = Xgb[0,:,:]\n",
    "    Gbin       = Gbin.reshape(dim)\n",
    "    pos        = np.asarray(range(0, dim))    \n",
    "    sel_index  = pos[Gbin == 1]\n",
    "    num_feat   = len(sel_index)\n",
    "    # Create dictionary\n",
    "    ga_data = {'sf': sel_index, 'c': curve, 'nf': num_feat}\n",
    "    \n",
    "    return ga_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:43:42.546451Z",
     "iopub.status.busy": "2022-12-14T11:43:42.546066Z",
     "iopub.status.idle": "2022-12-14T11:43:42.551469Z",
     "shell.execute_reply": "2022-12-14T11:43:42.550321Z",
     "shell.execute_reply.started": "2022-12-14T11:43:42.546418Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = {'xt':X_train, 'yt':y_train, 'xv':X_val, 'yv':y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:43:43.733389Z",
     "iopub.status.busy": "2022-12-14T11:43:43.732994Z",
     "iopub.status.idle": "2022-12-14T11:43:43.740116Z",
     "shell.execute_reply": "2022-12-14T11:43:43.739021Z",
     "shell.execute_reply.started": "2022-12-14T11:43:43.733354Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:43:44.397336Z",
     "iopub.status.busy": "2022-12-14T11:43:44.396946Z",
     "iopub.status.idle": "2022-12-14T11:43:44.402858Z",
     "shell.execute_reply": "2022-12-14T11:43:44.401675Z",
     "shell.execute_reply.started": "2022-12-14T11:43:44.397299Z"
    }
   },
   "outputs": [],
   "source": [
    "P    = 0.8       # switch probability\n",
    "k     = 5     # k-value in KNN\n",
    "N     = 20    # number of\n",
    "T     = 10   # maximum number of iterations\n",
    "opts = {'k':k, 'fold':fold, 'N':N, 'T':T, 'P':P}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T11:43:45.634826Z",
     "iopub.status.busy": "2022-12-14T11:43:45.633740Z",
     "iopub.status.idle": "2022-12-14T11:43:45.691383Z",
     "shell.execute_reply": "2022-12-14T11:43:45.688448Z",
     "shell.execute_reply.started": "2022-12-14T11:43:45.634784Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform feature selection\n",
    "start_time = time.time()\n",
    "fmdl  = jfs(X_train, y_train, opts)\n",
    "print(\"Run Time --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "sf    = fmdl['sf']\n",
    "\n",
    "# model with selected features\n",
    "x_train   = trainX_f[:, :,  sf]\n",
    "x_tes   = testX_f[:, :, sf]\n",
    "x_val = valX_f[:, :, sf]\n",
    "\n",
    "num_test = np.size(x_test, 0)\n",
    "    \n",
    "# Training\n",
    "model_LSTM = build_LSTM_classifier(input_shape, classes)\n",
    "# Train the model\n",
    "history_LSTM = model_LSTM.fit(\n",
    "        [x_train],\n",
    "        y = ytrain,\n",
    "        batch_size = 16,\n",
    "        epochs = 50,\n",
    "        validation_data=(x_val, yvalid),\n",
    "        callbacks = [\n",
    "            tfk.callbacks.EarlyStopping(monitor='val_loss', mode='max', patience=10, restore_best_weights=True),\n",
    "            tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience = 3, verbose=1,factor=0.3, min_lr=0.000001),\n",
    "            tfk.callbacks.ModelCheckpoint('LSTM.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "        ]\n",
    "    ).history\n",
    "# Prediction\n",
    "ypred   = model_LSTM.predict(x_test)\n",
    "acc     = np.sum(y_test == ypred) / num_test\n",
    "\n",
    "# Prediction\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# number of selected features\n",
    "num_feat = fmdl['nf']\n",
    "print(\"Feature Size:\", num_feat)\n",
    "\n",
    "# plot convergence\n",
    "curve   = fmdl['c']\n",
    "curve   = curve.reshape(np.size(curve,1))\n",
    "x       = np.arange(0, opts['T'], 1.0) + 1.0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, curve, 'o-')\n",
    "ax.set_xlabel('Number of Iterations')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('Genetic')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
